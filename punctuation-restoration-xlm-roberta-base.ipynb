{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shakil72/punctuation-restoration-xlm-roberta-base?scriptVersionId=159937838\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"f537f3bd","metadata":{"execution":{"iopub.execute_input":"2024-01-22T05:34:45.754479Z","iopub.status.busy":"2024-01-22T05:34:45.753787Z","iopub.status.idle":"2024-01-22T05:34:49.97793Z","shell.execute_reply":"2024-01-22T05:34:49.976332Z"},"papermill":{"duration":4.236366,"end_time":"2024-01-22T05:34:49.981438","exception":false,"start_time":"2024-01-22T05:34:45.745072","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'punctuation-restoration'...\r\n","remote: Enumerating objects: 348, done.\u001b[K\r\n","remote: Counting objects: 100% (87/87), done.\u001b[K\r\n","remote: Compressing objects: 100% (71/71), done.\u001b[K\r\n","remote: Total 348 (delta 45), reused 29 (delta 13), pack-reused 261\u001b[K\r\n","Receiving objects: 100% (348/348), 15.96 MiB | 8.03 MiB/s, done.\r\n","Resolving deltas: 100% (205/205), done.\r\n"]}],"source":["! git clone https://github.com/shakilsustswe/punctuation-restoration\n","# ! git clone https://github.com/xashru/punctuation-restoration.git"]},{"cell_type":"code","execution_count":2,"id":"f6c8241b","metadata":{"execution":{"iopub.execute_input":"2024-01-22T05:34:50.000667Z","iopub.status.busy":"2024-01-22T05:34:50.000173Z","iopub.status.idle":"2024-01-22T05:34:50.008874Z","shell.execute_reply":"2024-01-22T05:34:50.007692Z"},"papermill":{"duration":0.02171,"end_time":"2024-01-22T05:34:50.011228","exception":false,"start_time":"2024-01-22T05:34:49.989518","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/punctuation-restoration\n"]}],"source":["cd punctuation-restoration/"]},{"cell_type":"code","execution_count":3,"id":"b944a99b","metadata":{"execution":{"iopub.execute_input":"2024-01-22T05:34:50.029559Z","iopub.status.busy":"2024-01-22T05:34:50.029119Z","iopub.status.idle":"2024-01-22T05:35:05.916418Z","shell.execute_reply":"2024-01-22T05:35:05.915158Z"},"papermill":{"duration":15.899682,"end_time":"2024-01-22T05:35:05.919683","exception":false,"start_time":"2024-01-22T05:34:50.020001","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\r\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\r\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\r\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\r\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\r\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\r\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\r\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\r\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\r\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\r\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\r\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":4,"id":"a80cccaa","metadata":{"execution":{"iopub.execute_input":"2024-01-22T05:35:05.937671Z","iopub.status.busy":"2024-01-22T05:35:05.937277Z","iopub.status.idle":"2024-01-22T05:35:20.602515Z","shell.execute_reply":"2024-01-22T05:35:20.601183Z"},"papermill":{"duration":14.677852,"end_time":"2024-01-22T05:35:20.605547","exception":false,"start_time":"2024-01-22T05:35:05.927695","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-crf\r\n","  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\r\n","Installing collected packages: pytorch-crf\r\n","Successfully installed pytorch-crf-0.7.2\r\n"]}],"source":["!pip install pytorch-crf"]},{"cell_type":"code","execution_count":5,"id":"40a23a0b","metadata":{"execution":{"iopub.execute_input":"2024-01-22T05:35:20.62453Z","iopub.status.busy":"2024-01-22T05:35:20.624115Z","iopub.status.idle":"2024-01-22T05:35:20.628974Z","shell.execute_reply":"2024-01-22T05:35:20.627774Z"},"papermill":{"duration":0.017493,"end_time":"2024-01-22T05:35:20.631523","exception":false,"start_time":"2024-01-22T05:35:20.61403","status":"completed"},"tags":[]},"outputs":[],"source":["# pip install -r requirements.txt"]},{"cell_type":"code","execution_count":6,"id":"761f4672","metadata":{"execution":{"iopub.execute_input":"2024-01-22T05:35:20.650649Z","iopub.status.busy":"2024-01-22T05:35:20.650253Z","iopub.status.idle":"2024-01-22T06:03:28.831699Z","shell.execute_reply":"2024-01-22T06:03:28.827632Z"},"papermill":{"duration":1688.195889,"end_time":"2024-01-22T06:03:28.835991","exception":false,"start_time":"2024-01-22T05:35:20.640102","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\r\n","  warnings.warn(\r\n","Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\r\n","pip install xformers.\r\n","Using TensorFlow backend\r\n","Downloading (…)tencepiece.bpe.model: 100%|█| 5.07M/5.07M [00:00<00:00, 12.0MB/s]\r\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\r\n","loading file added_tokens.json from cache at None\r\n","loading file special_tokens_map.json from cache at None\r\n","loading file tokenizer_config.json from cache at None\r\n","Downloading config.json: 100%|█████████████████| 615/615 [00:00<00:00, 3.41MB/s]\r\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\r\n","Model config XLMRobertaConfig {\r\n","  \"_name_or_path\": \"xlm-roberta-base\",\r\n","  \"architectures\": [\r\n","    \"XLMRobertaForMaskedLM\"\r\n","  ],\r\n","  \"attention_probs_dropout_prob\": 0.1,\r\n","  \"bos_token_id\": 0,\r\n","  \"classifier_dropout\": null,\r\n","  \"eos_token_id\": 2,\r\n","  \"hidden_act\": \"gelu\",\r\n","  \"hidden_dropout_prob\": 0.1,\r\n","  \"hidden_size\": 768,\r\n","  \"initializer_range\": 0.02,\r\n","  \"intermediate_size\": 3072,\r\n","  \"layer_norm_eps\": 1e-05,\r\n","  \"max_position_embeddings\": 514,\r\n","  \"model_type\": \"xlm-roberta\",\r\n","  \"num_attention_heads\": 12,\r\n","  \"num_hidden_layers\": 12,\r\n","  \"output_past\": true,\r\n","  \"pad_token_id\": 1,\r\n","  \"position_embedding_type\": \"absolute\",\r\n","  \"transformers_version\": \"4.33.0\",\r\n","  \"type_vocab_size\": 1,\r\n","  \"use_cache\": true,\r\n","  \"vocab_size\": 250002\r\n","}\r\n","\r\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\r\n","Model config XLMRobertaConfig {\r\n","  \"architectures\": [\r\n","    \"XLMRobertaForMaskedLM\"\r\n","  ],\r\n","  \"attention_probs_dropout_prob\": 0.1,\r\n","  \"bos_token_id\": 0,\r\n","  \"classifier_dropout\": null,\r\n","  \"eos_token_id\": 2,\r\n","  \"hidden_act\": \"gelu\",\r\n","  \"hidden_dropout_prob\": 0.1,\r\n","  \"hidden_size\": 768,\r\n","  \"initializer_range\": 0.02,\r\n","  \"intermediate_size\": 3072,\r\n","  \"layer_norm_eps\": 1e-05,\r\n","  \"max_position_embeddings\": 514,\r\n","  \"model_type\": \"xlm-roberta\",\r\n","  \"num_attention_heads\": 12,\r\n","  \"num_hidden_layers\": 12,\r\n","  \"output_past\": true,\r\n","  \"pad_token_id\": 1,\r\n","  \"position_embedding_type\": \"absolute\",\r\n","  \"transformers_version\": \"4.33.0\",\r\n","  \"type_vocab_size\": 1,\r\n","  \"use_cache\": true,\r\n","  \"vocab_size\": 250002\r\n","}\r\n","\r\n","Downloading model.safetensors: 100%|████████| 1.12G/1.12G [00:04<00:00, 246MB/s]\r\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\r\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\r\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n","All the weights of XLMRobertaModel were initialized from the model checkpoint at xlm-roberta-base.\r\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaModel for predictions without further training.\r\n","train: 100%|██████████████████████████████████████| 1/1 [00:13<00:00, 13.99s/it]\r\n","epoch: 0, Train loss: 1.4231096506118774, Train accuracy: 0.06420233463035019\r\n","eval: 100%|█████████████████████████████████████| 42/42 [13:09<00:00, 18.80s/it]\r\n","epoch: 0, Val loss: 1.4143604267211187, Val accuracy: 0.07224755411926159\r\n","Best validation Acc: 0.07224755411926159\r\n","test: 100%|█████████████████████████████████████| 42/42 [13:40<00:00, 19.54s/it]\r\n","/kaggle/working/punctuation-restoration/src/train.py:194: RuntimeWarning: invalid value encountered in divide\r\n","  precision = tp/(tp+fp)\r\n","/kaggle/working/punctuation-restoration/src/train.py:196: RuntimeWarning: invalid value encountered in divide\r\n","  f1 = 2 * precision * recall / (precision + recall)\r\n","Precision: [       nan        nan 0.07229356 0.         0.07224755]\r\n","Recall: [0.         0.         1.         0.         0.61935484]\r\n","F1 score: [       nan        nan 0.13483912        nan 0.12940057]\r\n","Accuracy:0.07224755411926159\r\n","Confusion Matrix[[     0      0 159517    115]\r\n"," [     0      0   7493      0]\r\n"," [     0      0  13056      0]\r\n"," [     0      0    531      0]]\r\n","\r\n"]}],"source":["! python src/train.py --cuda=True --pretrained-model=xlm-roberta-base --freeze-bert=False --lstm-dim=-1 --language=bangla --seed=1 --lr=5e-6 --batch-size=32 --epoch=1 --use-crf=False --augment-type=all  --augment-rate=0.15 --alpha-sub=0.4 --alpha-del=0.4 --data-path=data --save-path=out"]},{"cell_type":"code","execution_count":7,"id":"0f1d4532","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:03:28.887259Z","iopub.status.busy":"2024-01-22T06:03:28.886039Z","iopub.status.idle":"2024-01-22T06:03:30.030903Z","shell.execute_reply":"2024-01-22T06:03:30.029363Z"},"papermill":{"duration":1.175365,"end_time":"2024-01-22T06:03:30.034339","exception":false,"start_time":"2024-01-22T06:03:28.858974","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/punctuation-restoration\r\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":8,"id":"52bf3a2e","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:03:30.081689Z","iopub.status.busy":"2024-01-22T06:03:30.080798Z","iopub.status.idle":"2024-01-22T06:04:17.045912Z","shell.execute_reply":"2024-01-22T06:04:17.044635Z"},"papermill":{"duration":46.992228,"end_time":"2024-01-22T06:04:17.048784","exception":false,"start_time":"2024-01-22T06:03:30.056556","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\r\n","  warnings.warn(\r\n","Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\r\n","pip install xformers.\r\n","Using TensorFlow backend\r\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\r\n","loading file added_tokens.json from cache at None\r\n","loading file special_tokens_map.json from cache at None\r\n","loading file tokenizer_config.json from cache at None\r\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\r\n","Model config XLMRobertaConfig {\r\n","  \"_name_or_path\": \"xlm-roberta-base\",\r\n","  \"architectures\": [\r\n","    \"XLMRobertaForMaskedLM\"\r\n","  ],\r\n","  \"attention_probs_dropout_prob\": 0.1,\r\n","  \"bos_token_id\": 0,\r\n","  \"classifier_dropout\": null,\r\n","  \"eos_token_id\": 2,\r\n","  \"hidden_act\": \"gelu\",\r\n","  \"hidden_dropout_prob\": 0.1,\r\n","  \"hidden_size\": 768,\r\n","  \"initializer_range\": 0.02,\r\n","  \"intermediate_size\": 3072,\r\n","  \"layer_norm_eps\": 1e-05,\r\n","  \"max_position_embeddings\": 514,\r\n","  \"model_type\": \"xlm-roberta\",\r\n","  \"num_attention_heads\": 12,\r\n","  \"num_hidden_layers\": 12,\r\n","  \"output_past\": true,\r\n","  \"pad_token_id\": 1,\r\n","  \"position_embedding_type\": \"absolute\",\r\n","  \"transformers_version\": \"4.33.0\",\r\n","  \"type_vocab_size\": 1,\r\n","  \"use_cache\": true,\r\n","  \"vocab_size\": 250002\r\n","}\r\n","\r\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\r\n","Model config XLMRobertaConfig {\r\n","  \"architectures\": [\r\n","    \"XLMRobertaForMaskedLM\"\r\n","  ],\r\n","  \"attention_probs_dropout_prob\": 0.1,\r\n","  \"bos_token_id\": 0,\r\n","  \"classifier_dropout\": null,\r\n","  \"eos_token_id\": 2,\r\n","  \"hidden_act\": \"gelu\",\r\n","  \"hidden_dropout_prob\": 0.1,\r\n","  \"hidden_size\": 768,\r\n","  \"initializer_range\": 0.02,\r\n","  \"intermediate_size\": 3072,\r\n","  \"layer_norm_eps\": 1e-05,\r\n","  \"max_position_embeddings\": 514,\r\n","  \"model_type\": \"xlm-roberta\",\r\n","  \"num_attention_heads\": 12,\r\n","  \"num_hidden_layers\": 12,\r\n","  \"output_past\": true,\r\n","  \"pad_token_id\": 1,\r\n","  \"position_embedding_type\": \"absolute\",\r\n","  \"transformers_version\": \"4.33.0\",\r\n","  \"type_vocab_size\": 1,\r\n","  \"use_cache\": true,\r\n","  \"vocab_size\": 250002\r\n","}\r\n","\r\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\r\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\r\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n","All the weights of XLMRobertaModel were initialized from the model checkpoint at xlm-roberta-base.\r\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaModel for predictions without further training.\r\n","Punctuated text\r\n","বিংশ। শতাব্দীর। বাংলা। মননে। কাজী। নজরুল। ইসলামের। মর্যাদা। ও। গুরুত্ব। অপরিসীম।। একাধারে। কবি। সাহিত্যিক। সংগীতজ্ঞ। সাংবাদিক। সম্পাদক। রাজনীতিবিদ। এবং। সৈনিক। হিসেবে। অন্যায়। ও। অবিচারের। বিরুদ্ধে। নজরুল। সর্বদাই। ছিলেন। সোচ্চার।। তার। কবিতা। ও। গানে। এই। মনোভাবই। প্রতিফলিত। হয়েছে।। অগ্নিবীণা। হাতে। তার। প্রবেশ। ধূমকেতুর। মতো। তার। প্রকাশ।। যেমন। লেখাতে। বিদ্রোহী। তেমনই। জীবনে। কাজেই। \"বিদ্রোহী। কবি\"। তার। জন্ম। ও। মৃত্যুবার্ষিকী। বিশেষ। মর্যাদার। সঙ্গে। উভয়। বাংলাতে। প্রতি। বৎসর। উদযাপিত। হয়ে। থাকে।। \r\n"]}],"source":["! python src/inference.py --pretrained-model=xlm-roberta-base --weight-path=out/weights.pt --language=bn --in-file=data/test_bn.txt --out-file=data/test_bn_out.txt"]},{"cell_type":"code","execution_count":9,"id":"758f0220","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:17.097573Z","iopub.status.busy":"2024-01-22T06:04:17.097122Z","iopub.status.idle":"2024-01-22T06:04:17.108273Z","shell.execute_reply":"2024-01-22T06:04:17.106855Z"},"papermill":{"duration":0.038976,"end_time":"2024-01-22T06:04:17.110924","exception":false,"start_time":"2024-01-22T06:04:17.071948","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/punctuation-restoration/data\n"]}],"source":["cd data/"]},{"cell_type":"code","execution_count":10,"id":"18fbb384","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:17.160445Z","iopub.status.busy":"2024-01-22T06:04:17.159974Z","iopub.status.idle":"2024-01-22T06:04:17.165115Z","shell.execute_reply":"2024-01-22T06:04:17.163833Z"},"papermill":{"duration":0.032922,"end_time":"2024-01-22T06:04:17.167625","exception":false,"start_time":"2024-01-22T06:04:17.134703","status":"completed"},"tags":[]},"outputs":[],"source":["# !gdown --id 1X2udyT1XYrmCNvWtFpT_6jrWsQejGCBW"]},{"cell_type":"code","execution_count":11,"id":"1f71a7c5","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:17.217432Z","iopub.status.busy":"2024-01-22T06:04:17.217029Z","iopub.status.idle":"2024-01-22T06:04:17.223513Z","shell.execute_reply":"2024-01-22T06:04:17.22237Z"},"papermill":{"duration":0.034106,"end_time":"2024-01-22T06:04:17.226142","exception":false,"start_time":"2024-01-22T06:04:17.192036","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/punctuation-restoration\n"]}],"source":["cd ../"]},{"cell_type":"code","execution_count":12,"id":"32826eec","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:17.275095Z","iopub.status.busy":"2024-01-22T06:04:17.274712Z","iopub.status.idle":"2024-01-22T06:04:18.365606Z","shell.execute_reply":"2024-01-22T06:04:18.364034Z"},"papermill":{"duration":1.119137,"end_time":"2024-01-22T06:04:18.368568","exception":false,"start_time":"2024-01-22T06:04:17.249431","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/punctuation-restoration\r\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":13,"id":"7e8e32c4","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:18.420528Z","iopub.status.busy":"2024-01-22T06:04:18.419044Z","iopub.status.idle":"2024-01-22T06:04:18.427483Z","shell.execute_reply":"2024-01-22T06:04:18.426025Z"},"papermill":{"duration":0.038105,"end_time":"2024-01-22T06:04:18.430277","exception":false,"start_time":"2024-01-22T06:04:18.392172","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/punctuation-restoration/out\n"]}],"source":["cd out/\n"]},{"cell_type":"code","execution_count":14,"id":"c44845d2","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:18.479166Z","iopub.status.busy":"2024-01-22T06:04:18.478776Z","iopub.status.idle":"2024-01-22T06:04:33.262224Z","shell.execute_reply":"2024-01-22T06:04:33.261142Z"},"papermill":{"duration":14.811414,"end_time":"2024-01-22T06:04:33.265067","exception":false,"start_time":"2024-01-22T06:04:18.453653","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gdown\r\n","  Downloading gdown-5.0.0-py3-none-any.whl (16 kB)\r\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\r\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\r\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\r\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\r\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\r\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\r\n","Installing collected packages: gdown\r\n","Successfully installed gdown-5.0.0\r\n"]}],"source":["!pip install gdown"]},{"cell_type":"code","execution_count":15,"id":"bdfd2b68","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:33.31536Z","iopub.status.busy":"2024-01-22T06:04:33.314889Z","iopub.status.idle":"2024-01-22T06:04:55.998522Z","shell.execute_reply":"2024-01-22T06:04:55.997312Z"},"papermill":{"duration":22.713141,"end_time":"2024-01-22T06:04:56.002492","exception":false,"start_time":"2024-01-22T06:04:33.289351","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/gdown/cli.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n","  warnings.warn(\r\n","Downloading...\r\n","From (original): https://drive.google.com/uc?id=1X2udyT1XYrmCNvWtFpT_6jrWsQejGCBW\r\n","From (redirected): https://drive.google.com/uc?id=1X2udyT1XYrmCNvWtFpT_6jrWsQejGCBW&confirm=t&uuid=85d15b2e-bddf-40d6-8020-b3f03ddfdaa1\r\n","To: /kaggle/working/punctuation-restoration/out/xlm-roberta-large-bn.pt\r\n","100%|███████████████████████████████████████| 2.31G/2.31G [00:20<00:00, 114MB/s]\r\n"]}],"source":["!gdown --id 1X2udyT1XYrmCNvWtFpT_6jrWsQejGCBW"]},{"cell_type":"code","execution_count":16,"id":"6970add7","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:56.222135Z","iopub.status.busy":"2024-01-22T06:04:56.221557Z","iopub.status.idle":"2024-01-22T06:04:56.230841Z","shell.execute_reply":"2024-01-22T06:04:56.229295Z"},"papermill":{"duration":0.098832,"end_time":"2024-01-22T06:04:56.233362","exception":false,"start_time":"2024-01-22T06:04:56.13453","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/punctuation-restoration\n"]}],"source":["cd ../\n"]},{"cell_type":"code","execution_count":17,"id":"0782b674","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:04:56.328648Z","iopub.status.busy":"2024-01-22T06:04:56.327744Z","iopub.status.idle":"2024-01-22T06:05:22.849648Z","shell.execute_reply":"2024-01-22T06:05:22.848331Z"},"papermill":{"duration":26.579552,"end_time":"2024-01-22T06:05:22.852241","exception":false,"start_time":"2024-01-22T06:04:56.272689","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\r\n","  warnings.warn(\r\n","Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\r\n","pip install xformers.\r\n","Using TensorFlow backend\r\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\r\n","loading file added_tokens.json from cache at None\r\n","loading file special_tokens_map.json from cache at None\r\n","loading file tokenizer_config.json from cache at None\r\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\r\n","Model config XLMRobertaConfig {\r\n","  \"_name_or_path\": \"xlm-roberta-base\",\r\n","  \"architectures\": [\r\n","    \"XLMRobertaForMaskedLM\"\r\n","  ],\r\n","  \"attention_probs_dropout_prob\": 0.1,\r\n","  \"bos_token_id\": 0,\r\n","  \"classifier_dropout\": null,\r\n","  \"eos_token_id\": 2,\r\n","  \"hidden_act\": \"gelu\",\r\n","  \"hidden_dropout_prob\": 0.1,\r\n","  \"hidden_size\": 768,\r\n","  \"initializer_range\": 0.02,\r\n","  \"intermediate_size\": 3072,\r\n","  \"layer_norm_eps\": 1e-05,\r\n","  \"max_position_embeddings\": 514,\r\n","  \"model_type\": \"xlm-roberta\",\r\n","  \"num_attention_heads\": 12,\r\n","  \"num_hidden_layers\": 12,\r\n","  \"output_past\": true,\r\n","  \"pad_token_id\": 1,\r\n","  \"position_embedding_type\": \"absolute\",\r\n","  \"transformers_version\": \"4.33.0\",\r\n","  \"type_vocab_size\": 1,\r\n","  \"use_cache\": true,\r\n","  \"vocab_size\": 250002\r\n","}\r\n","\r\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\r\n","Model config XLMRobertaConfig {\r\n","  \"architectures\": [\r\n","    \"XLMRobertaForMaskedLM\"\r\n","  ],\r\n","  \"attention_probs_dropout_prob\": 0.1,\r\n","  \"bos_token_id\": 0,\r\n","  \"classifier_dropout\": null,\r\n","  \"eos_token_id\": 2,\r\n","  \"hidden_act\": \"gelu\",\r\n","  \"hidden_dropout_prob\": 0.1,\r\n","  \"hidden_size\": 768,\r\n","  \"initializer_range\": 0.02,\r\n","  \"intermediate_size\": 3072,\r\n","  \"layer_norm_eps\": 1e-05,\r\n","  \"max_position_embeddings\": 514,\r\n","  \"model_type\": \"xlm-roberta\",\r\n","  \"num_attention_heads\": 12,\r\n","  \"num_hidden_layers\": 12,\r\n","  \"output_past\": true,\r\n","  \"pad_token_id\": 1,\r\n","  \"position_embedding_type\": \"absolute\",\r\n","  \"transformers_version\": \"4.33.0\",\r\n","  \"type_vocab_size\": 1,\r\n","  \"use_cache\": true,\r\n","  \"vocab_size\": 250002\r\n","}\r\n","\r\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/model.safetensors\r\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\r\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\r\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\r\n","All the weights of XLMRobertaModel were initialized from the model checkpoint at xlm-roberta-base.\r\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaModel for predictions without further training.\r\n","Traceback (most recent call last):\r\n","  File \"/kaggle/working/punctuation-restoration/src/inference.py\", line 105, in <module>\r\n","    inference()\r\n","  File \"/kaggle/working/punctuation-restoration/src/inference.py\", line 41, in inference\r\n","    deep_punctuation.load_state_dict(torch.load(model_save_path))\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 815, in load\r\n","    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 1043, in _legacy_load\r\n","    result = unpickler.load()\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 980, in persistent_load\r\n","    wrap_storage=restore_location(obj, location),\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 217, in default_restore_location\r\n","    result = fn(storage, location)\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 182, in _cuda_deserialize\r\n","    device = validate_cuda_device(location)\r\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/serialization.py\", line 166, in validate_cuda_device\r\n","    raise RuntimeError('Attempting to deserialize object on a CUDA '\r\n","RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\r\n"]}],"source":["! python src/inference.py --pretrained-model=xlm-roberta-base --weight-path=out/xlm-roberta-large-bn.pt --language=bn  --in-file=data/test_bn.txt --out-file=data/test_bn_out.txt"]},{"cell_type":"code","execution_count":18,"id":"e0e642c0","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:05:22.930145Z","iopub.status.busy":"2024-01-22T06:05:22.929725Z","iopub.status.idle":"2024-01-22T06:05:45.339878Z","shell.execute_reply":"2024-01-22T06:05:45.338304Z"},"papermill":{"duration":22.45205,"end_time":"2024-01-22T06:05:45.342674","exception":false,"start_time":"2024-01-22T06:05:22.890624","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\r\n","  warnings.warn(\r\n","/opt/conda/lib/python3.10/site-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\r\n","  warnings.warn(\r\n","Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\r\n","pip install xformers.\r\n","Using TensorFlow backend\r\n","loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/sentencepiece.bpe.model\r\n","loading file added_tokens.json from cache at None\r\n","loading file special_tokens_map.json from cache at None\r\n","loading file tokenizer_config.json from cache at None\r\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/77de1f7a7e5e737aead1cd880979d4f1b3af6668/config.json\r\n","Model config XLMRobertaConfig {\r\n","  \"_name_or_path\": \"xlm-roberta-base\",\r\n","  \"architectures\": [\r\n","    \"XLMRobertaForMaskedLM\"\r\n","  ],\r\n","  \"attention_probs_dropout_prob\": 0.1,\r\n","  \"bos_token_id\": 0,\r\n","  \"classifier_dropout\": null,\r\n","  \"eos_token_id\": 2,\r\n","  \"hidden_act\": \"gelu\",\r\n","  \"hidden_dropout_prob\": 0.1,\r\n","  \"hidden_size\": 768,\r\n","  \"initializer_range\": 0.02,\r\n","  \"intermediate_size\": 3072,\r\n","  \"layer_norm_eps\": 1e-05,\r\n","  \"max_position_embeddings\": 514,\r\n","  \"model_type\": \"xlm-roberta\",\r\n","  \"num_attention_heads\": 12,\r\n","  \"num_hidden_layers\": 12,\r\n","  \"output_past\": true,\r\n","  \"pad_token_id\": 1,\r\n","  \"position_embedding_type\": \"absolute\",\r\n","  \"transformers_version\": \"4.33.0\",\r\n","  \"type_vocab_size\": 1,\r\n","  \"use_cache\": true,\r\n","  \"vocab_size\": 250002\r\n","}\r\n","\r\n","Traceback (most recent call last):\r\n","  File \"/kaggle/working/punctuation-restoration/src/test.py\", line 33, in <module>\r\n","    test_files = os.listdir(args.data_path)\r\n","NotADirectoryError: [Errno 20] Not a directory: 'data/test_bn.txt'\r\n"]}],"source":["! python src/test.py --pretrained-model=xlm-roberta-base --lstm-dim=-1 --use-crf=False --data-path=data/test_bn.txt --weight-path=out/weights.pt --sequence-length=256 --save-path=out"]},{"cell_type":"code","execution_count":19,"id":"83e454b3","metadata":{"execution":{"iopub.execute_input":"2024-01-22T06:05:45.424694Z","iopub.status.busy":"2024-01-22T06:05:45.423777Z","iopub.status.idle":"2024-01-22T06:05:45.429397Z","shell.execute_reply":"2024-01-22T06:05:45.428185Z"},"papermill":{"duration":0.049356,"end_time":"2024-01-22T06:05:45.431999","exception":false,"start_time":"2024-01-22T06:05:45.382643","status":"completed"},"tags":[]},"outputs":[],"source":["# ! python src/test.py --pretrained-model=roberta-large --lstm-dim=-1 --use-crf=False --data-path=data/bn --weight-path=weights/roberta-large-en.pt --sequence-length=256 --save-path=out"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4320757,"sourceId":7425796,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":1864.894009,"end_time":"2024-01-22T06:05:45.998799","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-22T05:34:41.10479","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}